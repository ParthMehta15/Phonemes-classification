{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport csv\nimport random\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom sklearn.metrics import accuracy_score\nimport pandas as pd\n#!pip install --upgrade --force-reinstall --no-deps kaggle","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-03-03T06:08:10.030104Z","iopub.execute_input":"2022-03-03T06:08:10.030428Z","iopub.status.idle":"2022-03-03T06:08:12.192474Z","shell.execute_reply.started":"2022-03-03T06:08:10.03036Z","shell.execute_reply":"2022-03-03T06:08:12.191726Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Network(torch.nn.Module):\n    def __init__(self):\n        super(Network, self).__init__()\n        # TODO: Please try different architectures\n        in_size = 13*(2*24+1)  # 637\n#         def init_weights(m):\n#             if type(m) == nn.Linear:\n#                 torch.nn.init.kaiming_uniform_(m.weight, mode='fan_in',nonlinearity='leaky_relu')\n# #                 torch.nn.init.xavier_uniform_(m.weight)\n# #                 torch.nn.init.kaiming_normal_(m.weight, mode='fan_in')\n#                 m.bias.data.fill_(0.01)\n\n        layers = [\n            nn.Linear(in_size, 1024),\n            nn.BatchNorm1d(1024),\n            nn.LeakyReLU(),\n            nn.Linear(1024, 1024),\n            nn.BatchNorm1d(1024),\n            nn.LeakyReLU(),\n            nn.Dropout(p=0.3),\n            nn.Linear(1024, 2048),\n            nn.BatchNorm1d(2048),\n            nn.LeakyReLU(),\n            nn.Linear(2048, 1024),\n            nn.BatchNorm1d(1024),\n            nn.LeakyReLU(),\n            nn.Dropout(p=0.3),\n            nn.Linear(1024, 512),\n            nn.BatchNorm1d(512),\n            nn.LeakyReLU(),\n            nn.Linear(512, 256),\n            nn.BatchNorm1d(256),\n            nn.LeakyReLU(),\n            nn.Dropout(p=0.1),\n            nn.Linear(256, 40)\n        ]\n     \n        self.laysers = nn.Sequential(*layers)\n\n\n    def forward(self, A0):\n        x = self.laysers(A0)\n        return x","metadata":{"execution":{"iopub.status.busy":"2022-03-03T06:08:18.689763Z","iopub.execute_input":"2022-03-03T06:08:18.690047Z","iopub.status.idle":"2022-03-03T06:08:18.699862Z","shell.execute_reply.started":"2022-03-03T06:08:18.690016Z","shell.execute_reply":"2022-03-03T06:08:18.69881Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class LibriSamples(torch.utils.data.Dataset):\n    def __init__(self, data_path, sample=20000, shuffle=True, partition=\"dev-clean\", csvpath=None):\n        # sample represent how many npy files will be preloaded for one __getitem__ call\n        self.sample = sample \n        \n        self.X_dir = data_path + \"/\" + partition + \"/mfcc/\"\n        self.Y_dir = data_path + \"/\" + partition +\"/transcript/\"\n        \n        self.X_names = os.listdir(self.X_dir)\n        self.Y_names = os.listdir(self.Y_dir)\n\n        # using a small part of the dataset to debug\n        if csvpath:\n            subset = self.parse_csv(csvpath)\n            self.X_names = [i for i in self.X_names if i in subset]\n            self.Y_names = [i for i in self.Y_names if i in subset]\n\n        \n        if shuffle == True:\n            XY_names = list(zip(self.X_names, self.Y_names))\n            random.shuffle(XY_names)\n            self.X_names, self.Y_names = zip(*XY_names)\n        \n        assert(len(self.X_names) == len(self.Y_names))\n        self.length = len(self.X_names)\n        \n        self.PHONEMES = [\n            'SIL',   'AA',    'AE',    'AH',    'AO',    'AW',    'AY',  \n            'B',     'CH',    'D',     'DH',    'EH',    'ER',    'EY',\n            'F',     'G',     'HH',    'IH',    'IY',    'JH',    'K',\n            'L',     'M',     'N',     'NG',    'OW',    'OY',    'P',\n            'R',     'S',     'SH',    'T',     'TH',    'UH',    'UW',\n            'V',     'W',     'Y',     'Z',     'ZH',    '<sos>', '<eos>']\n      \n    @staticmethod\n    def parse_csv(filepath):\n        subset = []\n        with open(filepath) as f:\n            f_csv = csv.reader(f)\n            for row in f_csv:\n                subset.append(row[1])\n        return subset[1:]\n\n    def __len__(self):\n        return int(np.ceil(self.length / self.sample))\n        \n    def __getitem__(self, i):\n        sample_range = range(i*self.sample, min((i+1)*self.sample, self.length))\n        \n        X, Y = [], []\n        for j in sample_range:\n            X_path = self.X_dir + self.X_names[j]\n            Y_path = self.Y_dir + self.Y_names[j]\n            \n            label = [self.PHONEMES.index(yy) for yy in np.load(Y_path)][1:-1]\n\n            X_data = np.load(X_path)\n            X_data = (X_data - X_data.mean(axis=0))/X_data.std(axis=0)\n            X.append(X_data)\n            Y.append(np.array(label))\n            #print(Y)\n        X, Y = np.concatenate(X), np.concatenate(Y)\n        return X, Y\n    \nclass LibriItems(torch.utils.data.Dataset):\n    def __init__(self, X, Y, context = 0):\n        assert(X.shape[0] == Y.shape[0])\n        \n        self.length  = X.shape[0]\n        self.context = context\n\n        if context == 0:\n            self.X, self.Y = X, Y\n        else:\n            X = np.pad(X, ((context,context), (0,0)), 'constant', constant_values=(0,0))\n            self.X, self.Y = X, Y\n\n        \n    def __len__(self):\n        return self.length\n        \n    def __getitem__(self, i):\n        if self.context == 0:\n            xx = self.X[i].flatten()\n            yy = self.Y[i]\n        else:\n            xx = self.X[i:(i + 2*self.context + 1)].flatten()\n            yy = self.Y[i]\n        return xx, yy\n    \n\n\n","metadata":{"execution":{"iopub.status.busy":"2022-03-03T06:12:27.702712Z","iopub.execute_input":"2022-03-03T06:12:27.702988Z","iopub.status.idle":"2022-03-03T06:12:27.72519Z","shell.execute_reply.started":"2022-03-03T06:12:27.702959Z","shell.execute_reply":"2022-03-03T06:12:27.723797Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class LibriTesting(torch.utils.data.Dataset):\n    def __init__(self, data_path, sample=20000, shuffle=False, partition=\"test-clean\", csvpath=None):\n        # sample represent how many npy files will be preloaded for one __getitem__ call\n        \n        self.sample = sample \n\n        self.X_dir = data_path + \"/\" + partition + \"/mfcc/\"\n\n\n        if csvpath:\n\n            self.X_names = list(pd.read_csv(csvpath).file)\n\n            self.length = len(self.X_names)\n            \n        if shuffle == True:\n            XY_names = list(zip(self.X_names))\n            random.shuffle(XY_names)\n            self.X_names  = zip(*XY_names)\n        \n        self.length = len(self.X_names)\n        \n        self.PHONEMES = [\n            'SIL',   'AA',    'AE',    'AH',    'AO',    'AW',    'AY',  \n            'B',     'CH',    'D',     'DH',    'EH',    'ER',    'EY',\n            'F',     'G',     'HH',    'IH',    'IY',    'JH',    'K',\n            'L',     'M',     'N',     'NG',    'OW',    'OY',    'P',\n            'R',     'S',     'SH',    'T',     'TH',    'UH',    'UW',\n            'V',     'W',     'Y',     'Z',     'ZH',    '<sos>', '<eos>']\n      \n    @staticmethod\n    def parse_csv(filepath):\n        subset = []\n        with open(filepath) as f:\n            f_csv = csv.reader(f)\n            for row in f_csv:\n                subset.append(row[0])\n        return subset[1:]\n\n    def __len__(self):\n        return int(np.ceil(self.length / self.sample))\n        \n    def __getitem__(self, i):\n        sample_range = range(i*self.sample, min((i+1)*self.sample, self.length))\n        \n        X, Y = [], []\n        \n        for j in sample_range:\n            X_path = self.X_dir + self.X_names[j]\n            X_data = np.load(X_path)\n            label = [0 for i in range(X_data.shape[0])]\n            X_data = (X_data - X_data.mean(axis=0))/X_data.std(axis=0)\n            X.append(X_data)\n   \n        X = np.concatenate(X)\n        return X\n    \n    \n    \nclass LibriItemsTest(torch.utils.data.Dataset):\n    def __init__(self, X, context = 0):\n        \n        self.length  = X.shape[0]\n        self.context = context\n\n        if context == 0:\n            self.X = X \n        else:\n            X = np.pad(X, ((context,context), (0,0)), 'constant', constant_values=(0,0))\n            self.X = X\n\n        \n    def __len__(self):\n        return self.length\n        \n    def __getitem__(self, i):\n        if self.context == 0:\n            xx = self.X[i].flatten()\n\n        else:\n            xx = self.X[i:(i + 2*self.context + 1)].flatten()\n\n        return xx","metadata":{"execution":{"iopub.status.busy":"2022-03-03T06:12:28.217912Z","iopub.execute_input":"2022-03-03T06:12:28.218419Z","iopub.status.idle":"2022-03-03T06:12:28.236971Z","shell.execute_reply.started":"2022-03-03T06:12:28.218385Z","shell.execute_reply":"2022-03-03T06:12:28.235985Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ndef train(args, model, device, train_samples, optimizer, criterion, epoch):\n    model.train()\n    for i in range(len(train_samples)):\n        X, Y = train_samples[i]\n        train_items = LibriItems(X, Y, context=args['context'])\n        train_loader = torch.utils.data.DataLoader(train_items, batch_size=args['batch_size'], shuffle=True)\n\n        for batch_idx, (data, target) in enumerate(train_loader):\n            data = data.float().to(device)\n            target = target.long().to(device)\n\n            optimizer.zero_grad()\n            output = model(data)\n            loss = criterion(output, target)\n            loss.backward()\n            optimizer.step()\n            if batch_idx % args['log_interval'] == 0:\n                print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n                    epoch, batch_idx * len(data), len(train_loader.dataset),\n                    100. * batch_idx / len(train_loader), loss.item()))\n\n\ndef test(args, model, device, dev_samples):\n\n    model.eval()\n    true_y_list = []\n    pred_y_list = []\n    with torch.no_grad():\n        for i in range(len(dev_samples)):\n            X, Y = dev_samples[i]\n\n            test_items = LibriItems(X, Y, context=args['context'])\n            test_loader = torch.utils.data.DataLoader(test_items, batch_size=args['batch_size'], shuffle=False)\n\n            for data, true_y in test_loader:\n                data = data.float().to(device)\n                true_y = true_y.long().to(device)                \n\n                output = model(data)\n                pred_y = torch.argmax(output, axis=1)\n\n                pred_y_list.extend(pred_y.tolist())\n                true_y_list.extend(true_y.tolist())\n\n    train_accuracy =  accuracy_score(true_y_list, pred_y_list)\n    \n    \n    return train_accuracy\n    \ndef final_test(args, model, device, test_samples):\n\n    model.eval()\n    pred_y_list = []\n    with torch.no_grad():\n        for i in range(len(test_samples)):\n            X = test_samples[i]\n\n            test_items = LibriItemsTest(X,context=args['context'])\n            test_loader = torch.utils.data.DataLoader(test_items, batch_size=args['batch_size'], shuffle=False)\n\n            for data in test_loader:\n                data = data.float().to(device)                \n\n                output = model(data)\n                pred_y = torch.argmax(output, axis=1)\n\n                pred_y_list.extend(pred_y.tolist())\n            \n    return pred_y_list\n    \n    \n\n                    \n\ndef main(args):\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    \n    model = Network().to(device)\n    optimizer = optim.Adam(model.parameters(), lr=args['lr'])\n    criterion = torch.nn.CrossEntropyLoss()\n    \n#     train_samples = LibriSamples(data_path = args['LIBRI_PATH'], shuffle=True, partition=\"train-clean-100\", csvpath=\"/kaggle/input/11785hw1p2toy/h1p2_toy_data/train_filenames_subset_8192_v2.csv\")\n    train_samples = LibriSamples(data_path = args['LIBRI_PATH'], shuffle=True, partition=\"train-clean-100\", csvpath=None)\n\n    dev_samples = LibriSamples(data_path = args['LIBRI_PATH'], shuffle=True, partition=\"dev-clean\")\n\n    test_samples = LibriTesting(data_path = args['LIBRI_PATH'], shuffle=False, partition=\"test-clean\", csvpath=\"/kaggle/input/11-785-s22-hw1p2/test_order.csv\")\n\n    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.1, patience=4)\n    for epoch in range(1, args['epoch'] + 1):\n        train(args, model, device, train_samples, optimizer, criterion, epoch)\n        dev_acc = test(args, model, device, dev_samples)\n        scheduler.step(dev_acc)\n        print('Dev accuracy ', dev_acc)\n        if epoch%10==0:\n            train_acc = test(args, model, device, train_samples)\n            print('Train accuracy ', train_acc)\n            cur_lr = scheduler.optimizer.state_dict()['param_groups'][0]['lr']\n            print('Current LR: ', cur_lr)\n    \n    \n    final_train_acc = test(args, model, device, train_samples)\n    print('Final Train accuracy ', final_train_acc)\n    \n    output=final_test(args, model, device, test_samples)\n    print('Output_len:', len(output))\n    final_output=pd.DataFrame(output)\n    final_output.index.names = ['id']\n    final_output.columns =['label']\n    final_output.to_csv('/kaggle/working/final.csv')\n    \n\n\nif __name__ == '__main__':\n    args = {\n        'batch_size': 2048,\n        'context': 24,\n        'log_interval': 200,\n        'LIBRI_PATH': '/kaggle/input/11-785-s22-hw1p2/hw1p2_student_data',\n        'lr': 0.001,\n        'epoch': 50\n    }\n    main(args)","metadata":{"execution":{"iopub.status.busy":"2022-03-03T06:12:28.994587Z","iopub.execute_input":"2022-03-03T06:12:28.994841Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}